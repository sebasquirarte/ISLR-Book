# 1. Introduction

### An Overview of Statistical Learning

_**Supervised statistical learning**_ involves building a statistical model for predicting, or estimating, an output based on one or more inputs. 

_**Unsupervised statistical learning**_ has inputs but no supervising output; nevertheless we can learn relationships and structure from such data.

A _**regression**_ problem involves predicting a continuous or quantitative output value.

A _**classification**_  problem involves predicting the group or classification of an output value.

### A Brief History of Statistical Learning

At the beginning of the nineteenth century, the method of least squares was developed, implementing the earliest form of what is now known as _**linear regression**_. The approach was frst successfully applied to problems in astronomy. Linear regression is used for predicting quantitative values, such as an individualâ€™s salary.

In order to predict qualitative values, such as whether a patient survives or dies, or whether the stock market increases or decreases, linear discriminant analysis was proposed in 1936. In the 1940s, various authors put forth an alternative approach, _**logistic regression**_. In the early 1970s, the term _**generalized linear model**_ was developed to describe an entire class of statistical learning methods that include both linear and logistic regression as special cases.

In the mid 1980s, _**classifcation and regression trees**_ were developed, followed shortly by _**generalized additive models**_.
_**Neural networks**_ gained popularity in the 1980s, and _**support vector machines**_ arose in the 1990s.




